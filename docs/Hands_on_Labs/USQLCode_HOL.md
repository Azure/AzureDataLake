# Instructor-led Lab: Extensibility in U-SQL

# Introduction

In this lab you will learn how to several of the extensibility features in U-SQL, the new query language for Big Data. 

For additional Hands-On Labs for Azure Data Lake and U-SQL visit [http://aka.ms/AzureDataLakeHandsOnLabs](http://aka.ms/AzureDataLakeHandsOnLabs).

## What is U-SQL?
U-SQL is the Big Data query language of the Azure Data Lake Analytics (ADLA) service. 

U-SQL evolved from an internal Microsoft Big Data query language named SCOPE. 
It combines a familiar SQL-like declarative syntax with the extensibility and programmability provided by C# types 
and the C# expression language, together with support for Big Data processing concepts such as "schema on reads", custom processors and reducers.

U-SQL is not ANSI SQL, nor is it Transact-SQL. For starters, its keywords such as SELECT have to be in UPPERCASE. 
U-SQL uses the C# type system and within SELECT clauses, WHERE predicates, and so on, U-SQL uses C# expressions. This means the data types are C# types and use C# NULL semantics, and the comparison operators within a predicate follow C# syntax (e.g., a == "foo").

# Prerequisites
To complete this lab you'll need:

- A copy of Visual Studio with the [Azure Data Lake Tools for Visual Studio](http://aka.ms/adltoolsvs) installed, or access to the ADLA Portal.
- Access to an Azure Data Lake Analytics (ADLA) account (you can  use your own or use one that is provided for you in the classroom).

The lab exercises that follow provide only the language and scripts, and will not show you how to use the Azure Data Lake Tools for Visual Studio. Your instructor will show you how to run the scripts through Azure Data Lake Tools for Visual Studio.

# Introduction to the Lab

## Sample Data

The lab operates on sample tweet data provided by some volunteers. The data has been generated by downloading the tweets, mentions and retweets using the service at [http://www.tweetdownload.net](http://www.tweetdownload.net). The sample data should be available in your default storage account at location `/Samples/Data/Tweets` after installing the samples through the Azure Portal. The sample data set is also available at the [U-SQL Github site](https://github.com/Azure/usql/tree/master/Examples/Samples/Data/Tweets).

## Goals of the Lab

The main goals of the Lab are to teach you the following:

1. How to use C# expressions in your U-SQL scripts.
2. How to use the Visual Studio's U-SQL code behind capabilities.
3. How to share and re-use C# and .Net Code with others via U-SQL Assemblies.
4. How to write user-defined functions and a user-defined extractor.

In addition, you will use:

1. The U-SQL `SqlArray` type.
2. The U-SQL `CROSS APPLY` expression.
3. Ordering results during output.
4. U-SQL File Sets.

# Exercise 1: Writing C# expressions in U-SQL Expressions

In this exercise you will submit a U-SQL script that reads data from an input file, extracts and schematizes data, applies some C# expressions to process some of the extracted data and writes the results into an output file.

In particular, the script extracts the mentions from the tweet, counts the number of mentions in one of the tweet files, and outputs it in descending order of number of mentions.

1. Copy the following U-SQL script into the U-SQL script file (Script.usql) in Visual Studio:

        DECLARE @outdir = "<replace_this_with_your_output_name>";
        DECLARE @output = "/output/"+@outdir+"/result1.csv";

        @t =
           EXTRACT date   string,
                   time   string,
                   author string,
                   tweet  string
            FROM   "/Samples/Data/Tweets/MikeDoesBigDataTweets.csv"
           USING   Extractors.Csv();
        
        @m = 
           SELECT new SqlArray<string>(tweet.Split(' ').Where(w=>w.StartsWith("@"))) AS mentions 
           FROM   @t;

        @m = 
           SELECT mention
           FROM   @m CROSS APPLY EXPLODE(mentions) AS M(mention);

        @res =
           SELECT mention, COUNT(*) AS mentioncount
           FROM   @m
           GROUP BY mention; 

        OUTPUT @res
        TO @output
        ORDER BY mentioncount DESC
        USING Outputters.Csv();

2. Change the name of the output directory from *&lt;replace_this_with_your_output_name&gt;* to something unique.
3. Submit your script. 
	
This exercise illustrates the following concepts:

- *Rowset variables*. Each query expression that produces a rowset can be assigned to a variable. Variables in U-SQL follow the T-SQL variable naming pattern of an ampersand (@) followed by a name (for example **@t**). Note that the assignment statement does not execute the query. It merely names the expression and gives you the ability to build-up more complex expressions.

- *The EXTRACT expression*. This gives you the ability to define a schema as part of a read operation. For each column, the schema specifies a paired value consisting of a column name and a C# type name. It uses a so-called extractor, which can be created or customized by the user. However, in this case  we are using the built-in **Csv** (comma-separated value) extractor that is provided by the Extractors class, since the input data is comma.

- *The OUTPUT statement*. This takes a rowset and serializes it as a comma-separated file into the specified location. The `ORDER BY` clause will sort the output. Like extractors, outputters can be created or customized by the user. However, in this case we are using the built-in **Csv** (comma-separated value) outputter provided by the Outputters class.

- *C# Expression in SELECT query*. U-SQL uses C# as its expression language. This gives you access to all the built-in type methods (such as the `string` `Split` and `StartsWith` methods) as well as advanced C# expressions such as LINQ directly inside your U-SQL query.

- *SqlArray data type*. U-SQL provides the complex built-in types `SqlArray<>` and `SqlMap<,>`. Since an array contains potentially many items, the `EXPLODE` expression pivots each item into its own row.

- *CROSS APPLY Expression*. U-SQL offers the `CROSS APPLY` expression that applies a custom applier or the `EXPLODE` expression to each row and creates a new rowset from the rows returned by the applier/`EXPLODE`.

Assuming you are using a correctly-provisioned lab account, you should now have a file which contains the result of the query.

# Exercise 2: Using Visual Studio's Code-behind Capability

In this exercise, you will use the code-behind capabilities of Visual Studio to wrap the C# expression of Exercise 1 into a C# user-defined function.

1. Edit your U-SQL script to resemble the following:

        DECLARE @outdir = "<replace_this_with_your_output_name>";
        DECLARE @output = "/output/"+@outdir+"/result2.csv";

        @t =
           EXTRACT date   string,
                   time   string,
                   author string,
                   tweet  string
            FROM   "/Samples/Data/Tweets/MikeDoesBigDataTweets.csv"
           USING   Extractors.Csv();
        
        @m = 
           SELECT TweetAnalysis.Udfs.get_mentions(tweet) AS mentions 
           FROM   @t;

        @m = 
           SELECT mention
           FROM   @m CROSS APPLY EXPLODE(mentions) AS M(mention);

        @res =
           SELECT mention, COUNT(*) AS mentioncount
           FROM   @m
           GROUP BY mention; 

        OUTPUT @res
        TO @output
        ORDER BY mentioncount DESC
        USING Outputters.Csv();

2. As before, change the name of the output directory from *&lt;replace_this_with_your_output_name&gt;* to something unique.

3. Copy the following code into the code-behind file of the script (e.g., Script.usql.cs):

         using Microsoft.Analytics.Interfaces;
         using Microsoft.Analytics.Types.Sql;
         using System;
         using System.Collections.Generic;
         using System.IO;
         using System.Text;
         using System.Linq;
         
         namespace TweetAnalysis
         {
             public class Udfs
             {
                 public static SqlArray<string> get_mentions(string tweet)
                 {
                     return new SqlArray<string>(tweet.Split( ' ').Where(x => x.StartsWith("@")));
                 }
             }
         }

4. Submit your script, and verify that the result is the same as that of Exercise 1.

This exercise illustrates the following concepts:

- *VisualStudio's U-SQL Code-behind*. The Azure Data Lake Tools for VisualStudio offers the ability to write C# code in a code-behind file that the tool will automatically build and register in the Azure Data Lake account, add the necessary references to the script, and in the end remove the registered assembly to cleanup.

- *User-defined Functions*. U-SQL allows you to use any public static .Net function from referenced assemblies as user-defined functions. 

# Exercise 3: Create and register a U-SQL Assembly
In this exercise, you will create a new assembly in Visual Studio and register it in the ADLA account in order to share the previously introduced user-defined function with other users. 

First let's generate a database that is unique to you:

1. Add a new U-SQL Script file in the open Solution and copy the following U-SQL script:

        DROP DATABASE IF EXISTS <insert your DB name>;
        CREATE DATABASE <insert your DB name>;

2. Replace *&lt;insert your DB name&gt;* with a unique database name and then submit your query.
   This should create a new database.

Now let's add and register the assembly in Visual Studio:

3. Add a new **Class Library (For U-SQL Application)** project to the open solution (you can name it TweetAnalysis).

4. Move the C# code from Exercise 2 from the code-behind file into the Class Library's `.cs` file.

5. Right-click on the Class Library project and select Register Assembly.

6. Register the assembly in the database you created earlier with the name `TweetAnalysis` and submit the registration.

Now the assembly can be used in U-SQL Scripts:

7. Add the `REFERENCE ASSEMBLY` statement to the script file to make it look like (replace *&lt;insert your DB name&gt;* with the previously created database name):

        REFERENCE ASSEMBLY <insert your DB name>.TweetAnalysis;

        DECLARE @outdir = "<replace_this_with_your_output_name>";
        DECLARE @output = "/output/"+@outdir+"/result3.csv";

        @t =
           EXTRACT date   string,
                   time   string,
                   author string,
                   tweet  string
            FROM   "/Samples/Data/Tweets/MikeDoesBigDataTweets.csv"
           USING   Extractors.Csv();
        
        @m = 
           SELECT TweetAnalysis.Udfs.get_mentions(tweet) AS mentions 
           FROM   @t;

        @m = 
           SELECT mention
           FROM   @m CROSS APPLY EXPLODE(mentions) AS M(mention);

        @res =
           SELECT mention, COUNT(*) AS mentioncount
           FROM   @m
           GROUP BY mention; 

        OUTPUT @res
        TO @output
        ORDER BY mentioncount DESC
        USING Outputters.Csv();

8. Change the name of the output file from *&lt;replace_this_with_your_output_name&gt;* to something unique.
9. Submit your script, and verify that the result is the same as that of Exercise 1.

This exercise illustrates the following concepts:

- *U-SQL Assembly*. You can use U-SQL Assemblies to share your custom code with other users in Azure Data Lake as long as they have permissions to the database that contains the registered assembly. After referencing an assembly in a U-SQL Script, all the public classes and functions become available in U-SQL. 

# Exercise 4: User-defined Extractor

In this exercise, you will write a custom extractor for the tweet data set that will extracts the mentions and tweet topics as arrays (if the extract schema requests them).

First we create the custom extractor:

1. Add a **C# for U-SQL** class file to the TweetAnalysis C# Code project you created earlier and name it `TweetAnalysisExtractor.cs`.
2. Replace the content of `TweetAnalysisExtractor.cs` with the following custom extractor code:

        using Microsoft.Analytics.Interfaces;
        using Microsoft.Analytics.Types.Sql;
        using System;
        using System.Collections.Generic;
        using System.IO;
        using System.Linq;
        using System.Text;

        namespace TweetAnalysis
        {
            public static class UpdatableRowExtensions
            {
                public static void SetColumnIfExists<T>(this IUpdatableRow source, string colName, T value)
                {
                    var colIdx = source.Schema.IndexOf(colName);
                    if (colIdx != -1)
                    { source.Set<T>(colIdx, value); }
                }
            }

            [SqlUserDefinedExtractor(AtomicFileProcessing = false)]
            public class TweetAnalysisExtractor : IExtractor
            {
                private Encoding _encoding;
                private byte[] _row_delim;
                private string _col_delim;

                // Class initializer defines parameters for extractor
                public TweetAnalysisExtractor(Encoding encoding = null, string row_delim = "\r\n", string col_delim = ",")
                {
                    this._encoding = ((encoding == null) ? Encoding.UTF8 : encoding);
                    this._row_delim = this._encoding.GetBytes(row_delim);
                    this._col_delim = col_delim;
                }

                // get_topics
                public static SqlArray<string> get_topics(string tweet)
                {
                    return new SqlArray<string>(tweet.Split(' ').Where(x => x.StartsWith("#")));
                }

                public override IEnumerable<IRow> Extract(IUnstructuredReader input, IUpdatableRow output)
                {
                    foreach (Stream currentline in input.Split(this._row_delim))
                    {
                        using (StreamReader lineReader = new StreamReader(currentline, this._encoding))
                        {
                            string[] columns = lineReader.ReadToEnd().Split( new string[] { this._col_delim }
                                                                           , StringSplitOptions.None);

                            // row should have 4 columns: date, time, author, tweet
                            // extractor adds mentions and topics if requested
                            output.SetColumnIfExists("date", columns[0]);
                            output.SetColumnIfExists("time", columns[1]);
                            output.SetColumnIfExists("author", columns[2]);
                            output.SetColumnIfExists("tweet", columns[3]);
                            output.SetColumnIfExists("mentions", Udfs.get_mentions(columns[3]));
                            output.SetColumnIfExists("topics", get_topics(columns[3]));
                        }
                        yield return output.AsReadOnly();
                    }
                }
            }
        }

3. Right-click on the TweetAnalysis project and select **Register Assembly**. Name the assembly `TweetAnalysis`, select the option **Replace the assembly if it already exists**, and submit it.
    
Now we can change the script to make use of the custom extractor.

4. Change Script.usql to the following script:

        REFERENCE ASSEMBLY <insert your DB name>.TweetAnalysis;

        DECLARE @outdir = "<replace_this_with_your_output_name>";
        DECLARE @output = "/output/"+@outdir+"/result4.csv";

        @m =
           EXTRACT author   string,
                   mentions SqlArray<string>,
                   topics   SqlArray<string>
            FROM   "/Samples/Data/Tweets/MikeDoesBigDataTweets.csv"
           USING   new TweetAnalysis.TweetAnalysisExtractor();
        
        @m = 
           SELECT mention
           FROM   @m CROSS APPLY EXPLODE(mentions) AS M(mention);

        @res =
           SELECT mention, COUNT(*) AS mentioncount
           FROM   @m
           GROUP BY mention; 

        OUTPUT @res
        TO @output
        ORDER BY mentioncount DESC
        USING Outputters.Csv();

8. Change the name of the database from *&lt;insert your DB name&gt;* with the previously created database name and change the output path from *&lt;replace_this_with_your_output_name&gt;* to something unique.
9. Submit your script, and verify that the result is the same as that of Exercise 1.

This exercise illustrates the following concepts:

- *User-defined Extractor*. U-SQL provides an extensibility framework to add your own custom operators, called User-defined Operators or UDOs for short. This sample shows a custom extractor, but U-SQL also offers such custom operators such as processors, appliers, reducers, combiners and outputters. U-SQL custom extractors can be parallelised by U-SQL over a large file or you can force an extractor to operate on a complete file.

# Exercise 5: Using U-SQL File Sets

In this exercise, you will apply the previous script to all the tweet sample files.

1. Update the U-SQL script to look like the following:

        REFERENCE ASSEMBLY <insert your DB name>.TweetAnalysis;

        DECLARE @outdir = "<replace_this_with_your_output_name>";
        DECLARE @output = "/output/"+@outdir+"/result5.csv";

        @m =
           EXTRACT author   string,
                   mentions SqlArray<string>,
                   topics   SqlArray<string>,
                   origin   string
            FROM   "/Samples/Data/Tweets/{origin}Tweets.csv"
           USING   new TweetAnalysis.TweetAnalysisExtractor();
        
        @m = 
           SELECT mention
           FROM   @m CROSS APPLY EXPLODE(mentions) AS M(mention);

        @res =
           SELECT mention, COUNT(*) AS mentioncount
           FROM   @m
           GROUP BY mention; 

        OUTPUT @res
        TO @output
        ORDER BY mentioncount DESC
        USING Outputters.Csv();

2. Change the name of the database from *&lt;insert your DB name&gt;* with the previously created database name and change the output path from *&lt;replace_this_with_your_output_name&gt;* to something unique, and then submit the script.

This exercise illustrates the following concepts:

- *U-SQL File Set*. U-SQL provides a simple file path pattern language that allows you to parameterize the path expressions, lift parts of the path into your rowset data set as columns. Queries that put predicates on these columns can restrict the script to only run on the selected files without having to read all the files matching the patterns.

# Conclusion

This lab gave you a small taste of U-SQL's extensibility capabilites. 

We hope you come back and use Azure Data Lake Analytics and U-SQL for your Big Data processing needs!
